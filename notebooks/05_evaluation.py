# -*- coding: utf-8 -*-
"""05_evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uwESLfr7OZMkRxxCI0txEVBy9uUT3Ja5
"""

import pandas as pd
from sklearn.metrics import precision_recall_fscore_support, accuracy_score
import numpy as np
import matplotlib.pyplot as plt
import os
from transformers import BertTokenizer, TFBertModel
import tensorflow as tf
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.metrics.pairwise import cosine_similarity
from collections import Counter
import re

from sklearn.metrics import precision_recall_fscore_support, accuracy_score

def eval_retrieval(queries, ground_truth, k=5, model_type="bert"):
    """
    Evaluasi performa retrieval untuk model tertentu (BERT atau TF-IDF + SVM).

    Args:
        queries (list): List of query dictionaries with 'query_id', 'text', 'ground_truth_case_ids'.
        ground_truth (dict): Dictionary mapping query_id to ground truth case_ids.
        k (int): Number of retrieved cases to evaluate.
        model_type (str): Either 'bert' or 'tfidf_svm' to specify the model.

    Returns:
        dict: Metrics including accuracy, precision, recall, f1-score per query.
    """
    metrics = []

    for query in queries:
        query_id = query['query_id']
        query_text = query['text']
        ground_truth_ids = ground_truth.get(query_id, [])

        # Pilih fungsi retrieval berdasarkan model_type
        if model_type == "bert":
            retrieved_ids, _ = retrieve_bert(query_text, k=k)
        elif model_type == "tfidf_svm":
            retrieved_ids, _ = retrieve_tfidf_svm(query_text, k=k)
        else:
            raise ValueError("model_type harus 'bert' atau 'tfidf_svm'")

        # Konversi ke binary labels untuk metrik
        y_true = [1 if case_id in ground_truth_ids else 0 for case_id in retrieved_ids]
        y_pred = [1] * len(retrieved_ids)  # Semua retrieved dianggap positif

        # Tambahkan padding jika retrieved_ids kurang dari k
        while len(y_true) < k:
            y_true.append(0)
            y_pred.append(0)

        # Hitung metrik
        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)
        accuracy = accuracy_score(y_true, y_pred)

        metrics.append({
            'query_id': query_id,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'retrieved_ids': retrieved_ids,
            'ground_truth_ids': ground_truth_ids
        })

    return metrics

def eval_prediction(queries, ground_truth_categories, k=5, model_type="bert"):
    """
    Evaluasi performa prediksi kategori hukuman.

    Args:
        queries (list): List of query dictionaries with 'query_id', 'text'.
        ground_truth_categories (dict): Dictionary mapping query_id to ground truth category.
        k (int): Number of retrieved cases for majority voting.
        model_type (str): Either 'bert' or 'tfidf_svm'.

    Returns:
        dict: Metrics including accuracy, precision, recall, f1-score per query.
    """
    metrics = []

    for query in queries:
        query_id = query['query_id']
        query_text = query['text']
        true_category = ground_truth_categories.get(query_id, "Tidak Diketahui")

        # Pilih fungsi prediksi berdasarkan model_type
        if model_type == "bert":
            prediction = predict_outcome_with_majority_vote_bert(query_text, k=k)
        elif model_type == "tfidf_svm":
            prediction = predict_outcome_with_majority_vote_tfidf_svm(query_text, k=k)
        else:
            raise ValueError("model_type harus 'bert' atau 'tfidf_svm'")

        predicted_category = prediction['predicted_category']

        # Hitung metrik (binary: benar atau salah)
        y_true = [1 if true_category == predicted_category else 0]
        y_pred = [1]

        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)
        accuracy = accuracy_score(y_true, y_pred)

        metrics.append({
            'query_id': query_id,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'predicted_category': predicted_category,
            'ground_truth_category': true_category
        })

    return metrics

# Persiapkan ground truth
ground_truth = {q['query_id']: q['ground_truth_case_ids'] for q in data_uji}

# Asumsikan ground truth kategori berdasarkan case_id dari df
ground_truth_categories = {}
for query in data_uji:
    query_id = query['query_id']
    case_ids = query['ground_truth_case_ids']
    categories = [case_categories.get(cid, 'Lainnya') for cid in case_ids]
    # Ambil kategori mayoritas (jika ada beberapa case_id)
    if categories:
        ground_truth_categories[query_id] = max(set(categories), key=categories.count, default='Lainnya')
    else:
        ground_truth_categories[query_id] = 'Lainnya'

# Evaluasi retrieval untuk kedua model
retrieval_metrics_bert = eval_retrieval(data_uji, ground_truth, k=5, model_type="bert")
retrieval_metrics_tfidf_svm = eval_retrieval(data_uji, ground_truth, k=5, model_type="tfidf_svm")

# Evaluasi prediksi untuk kedua model
prediction_metrics_bert = eval_prediction(data_uji, ground_truth_categories, k=5, model_type="bert")
prediction_metrics_tfidf_svm = eval_prediction(data_uji, ground_truth_categories, k=5, model_type="tfidf_svm")

# Simpan metrik ke CSV
output_dir = "/content/eval"
os.makedirs(output_dir, exist_ok=True)

# Retrieval metrics
retrieval_metrics_df = pd.DataFrame([
    {'model': 'BERT', **m} for m in retrieval_metrics_bert
] + [
    {'model': 'TF-IDF + SVM', **m} for m in retrieval_metrics_tfidf_svm
])
retrieval_metrics_csv_path = f"{output_dir}/retrieval_metrics.csv"
retrieval_metrics_df.to_csv(retrieval_metrics_csv_path, index=False)
print(f"✅ File retrieval_metrics.csv disimpan ke: {retrieval_metrics_csv_path}")

# Prediction metrics
prediction_metrics_df = pd.DataFrame([
    {'model': 'BERT', **m} for m in prediction_metrics_bert
] + [
    {'model': 'TF-IDF + SVM', **m} for m in prediction_metrics_tfidf_svm
])
prediction_metrics_csv_path = f"{output_dir}/prediction_metrics.csv"
prediction_metrics_df.to_csv(prediction_metrics_csv_path, index=False)
print(f"✅ File prediction_metrics.csv disimpan ke: {prediction_metrics_csv_path}")

# Tabel rata-rata metrik per model
avg_metrics_retrieval = retrieval_metrics_df.groupby('model')[['accuracy', 'precision', 'recall', 'f1_score']].mean().reset_index()
avg_metrics_prediction = prediction_metrics_df.groupby('model')[['accuracy', 'precision', 'recall', 'f1_score']].mean().reset_index()

print("\n--- Tabel Rata-rata Metrik Retrieval ---")
print(avg_metrics_retrieval)
print("\n--- Tabel Rata-rata Metrik Prediksi ---")
print(avg_metrics_prediction)

# Visualisasi Bar Chart
plt.figure(figsize=(12, 6))
metrics = ['accuracy', 'precision', 'recall', 'f1_score']
x = np.arange(len(metrics))
width = 0.35

plt.bar(x - width/2, avg_metrics_retrieval.iloc[0][metrics], width, label='BERT (Retrieval)')
plt.bar(x + width/2, avg_metrics_retrieval.iloc[1][metrics], width, label='TF-IDF + SVM (Retrieval)')
plt.xlabel('Metrik')
plt.ylabel('Nilai')
plt.title('Perbandingan Performa Retrieval: BERT vs TF-IDF + SVM')
plt.xticks(x, metrics)
plt.legend()
plt.tight_layout()
plt.savefig(f"{output_dir}/retrieval_performance.png")
plt.show()

plt.figure(figsize=(12, 6))
plt.bar(x - width/2, avg_metrics_prediction.iloc[0][metrics], width, label='BERT (Prediksi)')
plt.bar(x + width/2, avg_metrics_prediction.iloc[1][metrics], width, label='TF-IDF + SVM (Prediksi)')
plt.xlabel('Metrik')
plt.ylabel('Nilai')
plt.title('Perbandingan Performa Prediksi: BERT vs TF-IDF + SVM')
plt.xticks(x, metrics)
plt.legend()
plt.tight_layout()
plt.savefig(f"{output_dir}/prediction_performance.png")
plt.show()